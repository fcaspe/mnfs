<section id="models">
    <div class="container">
        <div class="row">
            <div class="col-lg-12 text-center">
                <h2 class="section-heading">Pretrained models</h2>
                <h3 class="section-subheading text-muted">The provided models are trained from openly available datasets.</h3>
            </div>
        </div>
        <div class="row">
            <div class="col-lg-10 col-lg-offset-1">
                <div class="table-responsive">
                    <table class="table">
                        <thead>
                            <tr>
                                <th>Model</th>
                                <th>Dataset Description</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>Birdsong.h5</strong></td>
                                <td><a href='https://www.kaggle.com/datasets/rtatman/british-birdsong-dataset' target='_blank' rel='noopener noreferrer'>British Birdsong Dataset</a>, gathered from the <a href='http://www.xeno-canto.org/' target='_blank' rel='noopener noreferrer'>Xeno Canto collection</a>.</td>
                            </tr>
                            <tr>
                                <td><strong>LatinDrums.h5</strong></td>
                                <td><a href='https://zenodo.org/records/6533068' target='_blank' rel='noopener noreferrer'>Uruguayan candombe drumming</a> dataset.</td>
                            </tr>
                            <tr>
                                <td><strong>Drumset.h5</strong></td>
                                <td><a href='https://magenta.tensorflow.org/datasets/e-gmd' target='_blank' rel='noopener noreferrer'>The Expanded Groove MIDI Dataset</a>. 2h 50m of a drummer performing on an electronic drum kit.</td>
                            </tr>
                             <tr>
                                <td><strong>DxPiano.h5</strong></td>
                                <td>Trained using renders of Yamaha DX7 E. PIANO, synthesized with <a href='https://asb2m10.github.io/dexed/' target='_blank' rel='noopener noreferrer'>Dexed</a>.</td>
                            </tr>
                            <tr>
                                <td><strong>Vocals.h5</strong></td>
                                <td>Trained using the full corpus of the <a href='https://datashare.ed.ac.uk/handle/10283/2950' target='_blank' rel='noopener noreferrer'>VCTK Dataset</a>.</td>
                            </tr>
                            <tr>
                                <td><strong>filoSax.h5</strong></td>
                                <td>Trained using recordings of <em>Participant 1</em> from the <a href='https://dave-foster.github.io/filosax/' target='_blank' rel='noopener noreferrer'>Filosax Dataset</a>.</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                 <p class="text-muted text-center" style="margin-top: 20px;">Check <a href='https://github.com/fcaspe/BRAVE' target='_blank' rel='noopener noreferrer'>BRAVE's Repo</a> for instructions on how to train your own models. <a href='https://docs.google.com/forms/d/1nB1DjQSS-S3RNT1TiE_z2SoBZPDdIY2svXx1yg-z2fY' target='_blank' rel='noopener noreferrer'>Contact Me</a> if you would like to submit new models to the pretrained pack.</p>
            </div>
        </div>
    </div>
</section>